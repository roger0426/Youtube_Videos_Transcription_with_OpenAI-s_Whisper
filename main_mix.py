# å®‰è£å¿…è¦å¥—ä»¶ (è‹¥å°šæœªå®‰è£ï¼Œè«‹å…ˆåœ¨çµ‚ç«¯åŸ·è¡Œ)
# pip install yt-dlp openai-whisper openai pydub psutil

from string import punctuation
import yt_dlp
import whisper
import openai
from pydub import AudioSegment
import os
import time
import re
import psutil
import json
import getpass
import zhconv
from dotenv import load_dotenv

# === è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ===
load_dotenv()

# === æ¸…ç†æª”æ¡ˆåç¨±çš„å‡½æ•¸ ===
def clean_filename(filename):
    """æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤æˆ–æ›¿æ›ä¸å®‰å…¨çš„å­—ç¬¦"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = re.sub(r'\s+', ' ', filename).strip()
    filename = filename.strip('.')
    if len(filename) > 100:
        filename = filename[:100]
    return filename

# === ç³»çµ±è³‡æºæª¢æŸ¥ ===
def check_system_resources():
    """æª¢æŸ¥ç³»çµ±è³‡æºï¼Œè¿”å›å»ºè­°çš„æ¨¡å‹å¤§å°"""
    try:
        # æª¢æŸ¥å¯ç”¨è¨˜æ†¶é«” (GB)
        available_memory = psutil.virtual_memory().available / (1024**3)
        
        # æª¢æŸ¥ GPU è¨˜æ†¶é«” (å¦‚æœå¯ç”¨)
        gpu_memory = 0
        try:
            import torch
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        except ImportError:
            pass
        
        print(f"ç³»çµ±è¨˜æ†¶é«”: {available_memory:.1f} GB å¯ç”¨")
        if gpu_memory > 0:
            print(f"GPU è¨˜æ†¶é«”: {gpu_memory:.1f} GB")
        
        # æ ¹æ“šè³‡æºå»ºè­°æ¨¡å‹
        if gpu_memory >= 8:
            return "large"
        elif gpu_memory >= 4 or available_memory >= 8:
            return "medium"
        elif available_memory >= 4:
            return "small"
        else:
            return "base"
            
    except Exception as e:
        print(f"æª¢æŸ¥ç³»çµ±è³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return "base"

# === API Key ç®¡ç† ===
def load_api_key():
    """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ API Key"""
    return os.getenv('OPENAI_API_KEY')

def save_api_key(api_key):
    """å°‡ API Key å„²å­˜åˆ° .env æª”æ¡ˆ"""
    try:
        with open('.env', 'w', encoding='utf-8') as f:
            f.write(f'OPENAI_API_KEY={api_key}\n')
        print("âœ… API Key å·²å„²å­˜åˆ° .env æª”æ¡ˆ")
        return True
    except Exception as e:
        print(f"å„²å­˜ API Key æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def get_api_key():
    """å–å¾— API Keyï¼Œæä¾›å¤šç¨®å®‰å…¨æ–¹å¼"""
    # å˜—è©¦å¾ .env æª”æ¡ˆè¼‰å…¥
    api_key = load_api_key()
    if api_key:
        print("âœ… å¾ .env æª”æ¡ˆè®€å– API Key æˆåŠŸ")
        return api_key
    
    print("\nğŸ”‘ OpenAI API Key è¨­å®š")
    print("è«‹é¸æ“‡è¨­å®šæ–¹å¼:")
    print("1. æ‰‹å‹•è¼¸å…¥ (æ¨è–¦)")
    print("2. ç¨å¾Œè¨­å®šï¼ˆé€€å‡ºï¼‰")
    
    choice = input("è«‹é¸æ“‡ (1-2): ").strip()
    
    if choice == "1":
        print("\nè«‹è¼¸å…¥ä½ çš„ OpenAI API Key:")
        print("ğŸ’¡ æç¤º: è¼¸å…¥æ™‚ä¸æœƒé¡¯ç¤ºå…§å®¹ï¼Œé€™æ˜¯æ­£å¸¸çš„å®‰å…¨æ©Ÿåˆ¶")
        api_key = getpass.getpass("API Key: ").strip()
        
        if api_key and len(api_key) > 20:  # åŸºæœ¬é©—è­‰
            save_choice = input("æ˜¯å¦è¦å„²å­˜ API Key åˆ° .env æª”æ¡ˆä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨ï¼Ÿ(y/n): ").strip().lower()
            if save_choice == 'y':
                save_api_key(api_key)
            return api_key
        else:
            print("âŒ API Key æ ¼å¼ä¸æ­£ç¢º")
            return None
    
    return None

# === æœ¬åœ° Whisper è½‰éŒ„ ===
def transcribe_local(audio_path, model_size="base", language='zh'):
    """ä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹è½‰éŒ„"""
    try:
        print(f"è¼‰å…¥æœ¬åœ° Whisper æ¨¡å‹: {model_size}")
        model = whisper.load_model(model_size)
        print(f"é–‹å§‹è½‰éŒ„ (èªè¨€: {language})...")
        result = model.transcribe(audio_path, language=language, verbose=True, word_timestamps=True)
        return result
    except Exception as e:
        print(f"æœ¬åœ°è½‰éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === API Whisper è½‰éŒ„ ===
def transcribe_api(audio_file_path, client=None):
    """ä½¿ç”¨ OpenAI Whisper API è½‰éŒ„"""
    try:
        with open(audio_file_path, "rb") as audio_file:
            if client is None:
                client = openai.OpenAI()
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
            return response.text
    except Exception as e:
        print(f"API è½‰éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === GPT æ¨™é»ç¬¦è™Ÿè™•ç† ===
def add_punctuation_with_gpt(text_chunk, client):
    """ä½¿ç”¨ GPT ç‚ºæ–‡å­—ç‰‡æ®µæ·»åŠ æ¨™é»ç¬¦è™Ÿ"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡å­—ç·¨è¼¯åŠ©æ‰‹ã€‚è«‹ç‚ºä»¥ä¸‹æ²’æœ‰æ¨™é»ç¬¦è™Ÿçš„æ–‡å­—æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿï¼ŒåŒ…æ‹¬å¥è™Ÿã€é€—è™Ÿã€å•è™Ÿã€é©šå˜†è™Ÿç­‰ã€‚ä¿æŒåŸæ–‡çš„èªæ„å’Œçµæ§‹ï¼Œåªæ·»åŠ æ¨™é»ç¬¦è™Ÿã€‚"
                },
                {
                    "role": "user", 
                    "content": f"è«‹ç‚ºä»¥ä¸‹æ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼š\n\n{text_chunk}"
                }
            ],
            max_tokens=2000,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"GPT æ¨™é»ç¬¦è™Ÿè™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return text_chunk  # å¦‚æœå¤±æ•—ï¼Œè¿”å›åŸæ–‡

# === æ‰¹é‡æ¨™é»ç¬¦è™Ÿè™•ç† ===
def process_text_with_punctuation(text, client, chunk_size=100):
    """å°‡æ–‡å­—åˆ†å‰²æˆç‰‡æ®µï¼Œæ‰¹é‡è™•ç†æ¨™é»ç¬¦è™Ÿ"""
    print(f"\nğŸ“ é–‹å§‹æ¨™é»ç¬¦è™Ÿè™•ç†...")
    print(f"åŸå§‹æ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
    
    # æŒ‰ç©ºæ ¼åˆ†å‰²æ–‡å­—
    words = text.split(" ")
    if len(text) > 100 and len(words) < 5: # æ–‡å­—æœªè¢«åˆ†æ®µ
        chunk_size = 2000
    
    print(f"åˆ†å‰²æˆ {len(words)} å€‹å¥å­")
    
    # è¨ˆç®—éœ€è¦è™•ç†çš„ç‰‡æ®µæ•¸é‡
    total_chunks = (len(words) + chunk_size - 1) // chunk_size
    print(f"å°‡åˆ†æˆ {total_chunks} å€‹ç‰‡æ®µè™•ç†ï¼Œæ¯ç‰‡æ®µ {chunk_size} å€‹å¥å­")
    
    processed_chunks = []
    
    for i in range(0, len(words), chunk_size):
        chunk_num = i // chunk_size + 1
        chunk_words = words[i:i + chunk_size]
        chunk_text = " ".join(chunk_words)
        
        print(f"è™•ç†ç‰‡æ®µ {chunk_num}/{total_chunks} ({len(chunk_words)} å€‹å¥å­)...")
        
        # ä½¿ç”¨ GPT æ·»åŠ æ¨™é»ç¬¦è™Ÿ
        punctuated_chunk = add_punctuation_with_gpt(chunk_text, client)
        processed_chunks.append(punctuated_chunk)
        
        # æ·»åŠ å°å»¶é²é¿å… API é™åˆ¶
        time.sleep(0.5)
    
    # åˆä½µæ‰€æœ‰è™•ç†éçš„ç‰‡æ®µ
    final_text = " ".join(processed_chunks)
    print(f"âœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
    print(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(final_text)} å­—å…ƒ")
    
    return final_text

# === æ™ºèƒ½æ¨¡å‹é¸æ“‡ ===
def smart_model_selection(audio_path):
    """æ™ºèƒ½é¸æ“‡æœ€ä½³æ¨¡å‹"""
    print("\nğŸ¤– æ™ºèƒ½æ¨¡å‹é¸æ“‡æ¨¡å¼")
    
    # æª¢æŸ¥éŸ³è¨Šé•·åº¦
    try:
        audio = AudioSegment.from_file(audio_path)
        duration_minutes = len(audio) / (1000 * 60)
        print(f"éŸ³è¨Šé•·åº¦: {duration_minutes:.1f} åˆ†é˜")
    except:
        duration_minutes = 0
    
    # å»ºè­°çš„æ¨¡å‹é †åºï¼ˆå¾å¤§åˆ°å°ï¼‰
    model_order = ["large", "medium"] # "small", "base", "tiny"
    recommended = check_system_resources()
    
    print(f"ç³»çµ±å»ºè­°æ¨¡å‹: {recommended}")
    print("å°‡å¾æœ€å¤§æ¨¡å‹é–‹å§‹å˜—è©¦ï¼Œå¦‚æœå¤±æ•—æœƒè‡ªå‹•é™ç´š...")
    
    for model_size in model_order:
        print(f"\nå˜—è©¦ä½¿ç”¨ {model_size} æ¨¡å‹...")
        try:
            result = transcribe_local(audio_path, model_size)
            if result:
                print(f"âœ… {model_size} æ¨¡å‹è½‰éŒ„æˆåŠŸï¼")
                return result, model_size
            else:
                print(f"âŒ {model_size} æ¨¡å‹è½‰éŒ„å¤±æ•—")
        except Exception as e:
            print(f"âŒ {model_size} æ¨¡å‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            if "out of memory" in str(e).lower() or "cuda" in str(e).lower():
                print("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ä¸è¶³ï¼Œå˜—è©¦è¼ƒå°æ¨¡å‹...")
                continue
            else:
                print("å…¶ä»–éŒ¯èª¤ï¼Œå˜—è©¦è¼ƒå°æ¨¡å‹...")
                continue
    
    print("âŒ æ‰€æœ‰æœ¬åœ°æ¨¡å‹éƒ½å¤±æ•—äº†")
    return None, None

# === å–å¾—å½±ç‰‡è³‡è¨Š ===
def get_video_info(youtube_url):
    """å–å¾— YouTube å½±ç‰‡è³‡è¨Šè€Œä¸ä¸‹è¼‰"""
    try:
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print(f"æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š: {youtube_url}")
            info = ydl.extract_info(youtube_url, download=False)
            title = info.get('title', 'unknown')
            duration = info.get('duration', 0)
            uploader = info.get('uploader', 'unknown')
            
            return {
                'title': title,
                'duration': duration,
                'uploader': uploader,
                'url': youtube_url
            }
    except Exception as e:
        print(f"å–å¾—å½±ç‰‡è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === ä¸‹è¼‰ YouTube éŸ³è¨Š ===
def download_audio(youtube_url, audio_path="downloads"):
    """ä¸‹è¼‰ YouTube éŸ³è¨Šæª”æ¡ˆ"""
    try:
        if not os.path.exists(audio_path):
            os.makedirs(audio_path)
        
        # å…ˆå–å¾—å½±ç‰‡è³‡è¨Šä»¥ç²å–æ¨™é¡Œ
        ydl_info_opts = {
            'quiet': True,
            'no_warnings': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)
            title = info.get('title', 'unknown')
            clean_title = clean_filename(title)
        
        # ä½¿ç”¨æ¸…ç†å¾Œçš„æ¨™é¡Œä½œç‚ºæª”æ¡ˆåç¨±
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': os.path.join(audio_path, f'{clean_title}.%(ext)s'),
            'extractaudio': True,
            'audioformat': 'mp3',
            'noplaylist': True,
            'ignoreerrors': True,
            'no_warnings': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print(f"æ­£åœ¨ä¸‹è¼‰éŸ³è¨Š: {youtube_url}")
            print(f"åŸå§‹æ¨™é¡Œ: {title}")
            print(f"æ¸…ç†å¾Œæ¨™é¡Œ: {clean_title}")
            ydl.download([youtube_url])
            
            # å°‹æ‰¾ä¸‹è¼‰çš„æª”æ¡ˆ
            for file in os.listdir(audio_path):
                if file.startswith(clean_title) and file.endswith(('.mp3', '.m4a', '.webm', '.ogg')):
                    file_path = os.path.join(audio_path, file)
                    print(f"éŸ³è¨Šä¸‹è¼‰å®Œæˆ: {file}")
                    return file_path, clean_title
            
            raise Exception("æ‰¾ä¸åˆ°ä¸‹è¼‰çš„éŸ³è¨Šæª”æ¡ˆ")
        
    except Exception as e:
        print(f"ä¸‹è¼‰éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None

# === ä¸»ç¨‹å¼ ===
if __name__ == "__main__":
    print("ğŸµ æ™ºèƒ½èªéŸ³è½‰æ–‡å­—å·¥å…·")
    print("=" * 50)
    
    # å–å¾— YouTube ç¶²å€
    youtube_url = input("è¦è½‰éŒ„çš„YouTubeå½±ç‰‡ç¶²å€: ").strip()
    if not youtube_url:
        print("æœªæä¾›ç¶²å€ï¼Œç¨‹å¼çµæŸ")
        exit(1)
    
    # å…ˆå–å¾—å½±ç‰‡è³‡è¨Šè®“ä½¿ç”¨è€…ç¢ºèª
    print("\nğŸ“‹ æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š...")
    video_info = get_video_info(youtube_url)
    
    if not video_info:
        print("âŒ ç„¡æ³•å–å¾—å½±ç‰‡è³‡è¨Šï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
        exit(1)
    
    # é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
    print("\n" + "="*60)
    print("ğŸ“º å½±ç‰‡è³‡è¨Šç¢ºèª")
    print("="*60)
    print(f"æ¨™é¡Œ: {video_info['title']}")
    print(f"ä¸Šå‚³è€…: {video_info['uploader']}")
    if video_info['duration'] > 0:
        duration_minutes = video_info['duration'] / 60
        print(f"é•·åº¦: {duration_minutes:.1f} åˆ†é˜")
    print(f"ç¶²å€: {video_info['url']}")
    print("="*60)
    
    # è®“ä½¿ç”¨è€…ç¢ºèª
    print("\nè«‹ç¢ºèªæ˜¯å¦è¦è½‰éŒ„æ­¤å½±ç‰‡ï¼Ÿ")
    print("1. æ˜¯ï¼Œç¹¼çºŒè½‰éŒ„")
    print("2. å¦ï¼Œé‡æ–°è¼¸å…¥ç¶²å€")
    print("3. é€€å‡ºç¨‹å¼")
    
    confirm = input("è«‹é¸æ“‡ (1-3): ").strip()
    
    if confirm == "2":
        # é‡æ–°è¼¸å…¥ç¶²å€
        youtube_url = input("\nè«‹é‡æ–°è¼¸å…¥YouTubeå½±ç‰‡ç¶²å€: ").strip()
        if not youtube_url:
            print("æœªæä¾›ç¶²å€ï¼Œç¨‹å¼çµæŸ")
            exit(1)
        
        # é‡æ–°å–å¾—å½±ç‰‡è³‡è¨Š
        print("\nğŸ“‹ æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š...")
        video_info = get_video_info(youtube_url)
        
        if not video_info:
            print("âŒ ç„¡æ³•å–å¾—å½±ç‰‡è³‡è¨Šï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
            exit(1)
        
        # å†æ¬¡é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
        print("\n" + "="*60)
        print("ğŸ“º å½±ç‰‡è³‡è¨Šç¢ºèª")
        print("="*60)
        print(f"æ¨™é¡Œ: {video_info['title']}")
        print(f"ä¸Šå‚³è€…: {video_info['uploader']}")
        if video_info['duration'] > 0:
            duration_minutes = video_info['duration'] / 60
            print(f"é•·åº¦: {duration_minutes:.1f} åˆ†é˜")
        print(f"ç¶²å€: {video_info['url']}")
        print("="*60)
        
        # å†æ¬¡ç¢ºèª
        confirm = input("\nç¢ºèªè½‰éŒ„æ­¤å½±ç‰‡ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("ç¨‹å¼çµæŸ")
            exit(1)
            
    elif confirm == "3":
        print("ç¨‹å¼çµæŸ")
        exit(1)
    elif confirm != "1":
        print("ç„¡æ•ˆé¸æ“‡ï¼Œç¨‹å¼çµæŸ")
        exit(1)
    
    # é¸æ“‡è½‰éŒ„æ–¹å¼
    print("\nè«‹é¸æ“‡è½‰éŒ„æ–¹å¼:")
    print("1. æ™ºèƒ½æ¨¡å¼ (å„ªå…ˆæœ¬åœ°ï¼Œå¤±æ•—æ™‚ä½¿ç”¨API)")
    print("2. æœ¬åœ°æ¨¡å¼ (åƒ…ä½¿ç”¨æœ¬åœ°æ¨¡å‹)")
    print(f"3. APIæ¨¡å¼ (åƒ…ä½¿ç”¨OpenAI APIï¼Œé ä¼°è™•ç†åƒ¹æ ¼ï¼š{round(0.2*duration_minutes, 2)}å…ƒ)")
    
    mode = input("è«‹é¸æ“‡ (1-3): ").strip()
    
    # ä¸‹è¼‰éŸ³è¨Š
    print("\né–‹å§‹ä¸‹è¼‰éŸ³è¨Š...")
    max_retries = 3
    audio_file = None
    video_title = None
    
    for attempt in range(max_retries):
        print(f"å˜—è©¦ç¬¬ {attempt + 1} æ¬¡ä¸‹è¼‰...")
        result = download_audio(youtube_url)
        if result and result[0]:
            audio_file, video_title = result
            break
        if attempt < max_retries - 1:
            print("ç­‰å¾… 3 ç§’å¾Œé‡è©¦...")
            time.sleep(3)
    
    if not audio_file or not video_title:
        print("âŒ ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
        exit(1)
    
    print(f"âœ… éŸ³è¨Šä¸‹è¼‰æˆåŠŸ: {video_title}")
    
    # æ ¹æ“šé¸æ“‡çš„æ¨¡å¼é€²è¡Œè½‰éŒ„
    transcript = None
    used_method = ""
    
    if mode == "1":  # æ™ºèƒ½æ¨¡å¼
        print("\nğŸ¤– æ™ºèƒ½æ¨¡å¼å•Ÿå‹•")
        # å…ˆå˜—è©¦æœ¬åœ°
        transcript, model_used = smart_model_selection(audio_file)
        if transcript:
            used_method = f"æœ¬åœ°æ¨¡å‹ ({model_used})"
        else:
            print("\næœ¬åœ°è½‰éŒ„å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨ API...")
            api_key = get_api_key()
            if api_key:
                client = openai.OpenAI(api_key=api_key)
                transcript_text = transcribe_api(audio_file, client)
                if transcript_text:
                    transcript = {"text": transcript_text}
                    used_method = "OpenAI API"
                else:
                    print("âŒ API è½‰éŒ„ä¹Ÿå¤±æ•—äº†")
            else:
                print("âŒ ç„¡æ³•å–å¾— API Keyï¼Œè½‰éŒ„å¤±æ•—")
    
    elif mode == "2":  # æœ¬åœ°æ¨¡å¼
        print("\nğŸ’» æœ¬åœ°æ¨¡å¼")
        model_size = input("è«‹é¸æ“‡æ¨¡å‹å¤§å° (large/medium/small/base/tiny), è¶Šå¤§å“è³ªè¶Šå¥½: ").strip() or "base"
        transcript = transcribe_local(audio_file, model_size)
        if transcript:
            used_method = f"æœ¬åœ°æ¨¡å‹ ({model_size})"
    
    elif mode == "3":  # APIæ¨¡å¼
        print("\nğŸŒ APIæ¨¡å¼")
        api_key = get_api_key()
        if api_key:
            print("æ­£åœ¨ä½¿ç”¨ API è½‰éŒ„...")
            client = openai.OpenAI(api_key=api_key)
            transcript_text = transcribe_api(audio_file, client)
            if transcript_text:
                transcript = {"text": transcript_text}
                used_method = "OpenAI API"
        else:
            print("âŒ ç„¡æ³•å–å¾— API Key")
    
    # å„²å­˜çµæœ
    if transcript:
        output_path = "output"
        if not os.path.exists(output_path):
            os.makedirs(output_path)
        output_filename = os.path.join(output_path, f"{video_title}.txt")
        traditional_text = zhconv.convert(transcript["text"], 'zh-hant')
        # è©¢å•æ˜¯å¦è¦æ·»åŠ æ¨™é»ç¬¦è™Ÿ
        print(f"\nğŸ“ è½‰éŒ„å®Œæˆï¼åŸå§‹æ–‡å­—é•·åº¦: {len(traditional_text)} å­—å…ƒ")
        print("\næ˜¯å¦è¦ä½¿ç”¨ GPT ç‚ºæ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼Ÿ")
        print("1. æ˜¯ï¼Œæ·»åŠ æ¨™é»ç¬¦è™Ÿ (éœ€è¦ OpenAI API Key)")
        print("2. å¦ï¼Œç›´æ¥å„²å­˜åŸå§‹æ–‡å­—")
        
        punctuation_choice = input("è«‹é¸æ“‡ (1-2): ").strip()
        
        if punctuation_choice == "1":
            # éœ€è¦ API Key é€²è¡Œæ¨™é»ç¬¦è™Ÿè™•ç†
            api_key = get_api_key()
            if api_key:
                client = openai.OpenAI(api_key=api_key)
                punctuated_text = process_text_with_punctuation(traditional_text, client)
                
                # å„²å­˜å¸¶æ¨™é»ç¬¦è™Ÿçš„ç‰ˆæœ¬
                with open(output_filename, "w", encoding="utf-8") as f:
                    f.write(punctuated_text)
                
                print(f"\nâœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
                print(f"ä½¿ç”¨æ–¹æ³•: {used_method} + GPTæ¨™é»ç¬¦è™Ÿè™•ç†")
                print(f"è¼¸å‡ºæª”æ¡ˆ: {output_filename}")
                print(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(punctuated_text)} å­—å…ƒ")
            else:
                print("âŒ ç„¡æ³•å–å¾— API Keyï¼Œå„²å­˜åŸå§‹æ–‡å­—")
                with open(output_filename, "w", encoding="utf-8") as f:
                    f.write(traditional_text)
                print(f"âœ… è½‰éŒ„å®Œæˆï¼")
                print(f"ä½¿ç”¨æ–¹æ³•: {used_method}")
                print(f"è¼¸å‡ºæª”æ¡ˆ: {output_filename}")
                print(f"é€å­—ç¨¿é•·åº¦: {len(traditional_text)} å­—å…ƒ")
        else:
            # ç›´æ¥å„²å­˜åŸå§‹æ–‡å­—
            with open(output_filename, "w", encoding="utf-8") as f:
                f.write(traditional_text)
            
            print(f"\nâœ… è½‰éŒ„å®Œæˆï¼")
            print(f"ä½¿ç”¨æ–¹æ³•: {used_method}")
            print(f"è¼¸å‡ºæª”æ¡ˆ: {output_filename}")
            print(f"é€å­—ç¨¿é•·åº¦: {len(traditional_text)} å­—å…ƒ")
    else:
        print("\nâŒ è½‰éŒ„å¤±æ•—")
