# å®‰è£å¿…è¦å¥—ä»¶ (è‹¥å°šæœªå®‰è£ï¼Œè«‹å…ˆåœ¨çµ‚ç«¯åŸ·è¡Œ)
# pip install yt-dlp openai-whisper openai pydub psutil

from string import punctuation
import yt_dlp
import whisper
import openai
from pydub import AudioSegment
import os
import time
import re
import psutil
import json
import getpass
import zhconv
from dotenv import load_dotenv

# === è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ===
load_dotenv()

# === æ¸…ç†æª”æ¡ˆåç¨±çš„å‡½æ•¸ ===
def clean_filename(filename):
    """æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤æˆ–æ›¿æ›ä¸å®‰å…¨çš„å­—ç¬¦"""
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = re.sub(r'\s+', ' ', filename).strip()
    filename = filename.strip('.')
    if len(filename) > 100:
        filename = filename[:100]
    return filename

# === ç³»çµ±è³‡æºæª¢æŸ¥ ===
def check_system_resources():
    """æª¢æŸ¥ç³»çµ±è³‡æºï¼Œè¿”å›å»ºè­°çš„æ¨¡å‹å¤§å°"""
    try:
        # æª¢æŸ¥å¯ç”¨è¨˜æ†¶é«” (GB)
        available_memory = psutil.virtual_memory().available / (1024**3)
        
        # æª¢æŸ¥ GPU è¨˜æ†¶é«” (å¦‚æœå¯ç”¨)
        gpu_memory = 0
        gpu_type = "none"
        try:
            import torch
            if torch.backends.mps.is_available():
                # Mac GPU (M1/M2/M3)
                gpu_type = "mps"
                # Mac GPU è¨˜æ†¶é«”é€šå¸¸èˆ‡ç³»çµ±è¨˜æ†¶é«”å…±äº«ï¼Œä¼°ç®—å¯ç”¨è¨˜æ†¶é«”
                gpu_memory = available_memory * 0.5  # å‡è¨­ä¸€åŠå¯ç”¨çµ¦ GPU
            elif torch.cuda.is_available():
                # NVIDIA GPU
                gpu_type = "cuda"
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        except ImportError:
            pass
        
        print(f"ç³»çµ±è¨˜æ†¶é«”: {available_memory:.1f} GB å¯ç”¨")
        if gpu_memory > 0:
            print(f"GPU é¡å‹: {gpu_type.upper()}")
            print(f"GPU è¨˜æ†¶é«”: {gpu_memory:.1f} GB")
        
        # æ ¹æ“šè³‡æºå»ºè­°æ¨¡å‹
        if gpu_memory >= 8:
            return "large-v3"
        elif gpu_memory >= 4 or available_memory >= 8:
            return "medium"
        elif available_memory >= 4:
            return "small"
        else:
            return "base"
            
    except Exception as e:
        print(f"æª¢æŸ¥ç³»çµ±è³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return "base"

# === API Key ç®¡ç† ===
def load_api_key():
    """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ API Key"""
    return os.getenv('OPENAI_API_KEY')

def save_api_key(api_key):
    """å°‡ API Key å„²å­˜åˆ° .env æª”æ¡ˆ"""
    try:
        with open('.env', 'w', encoding='utf-8') as f:
            f.write(f'OPENAI_API_KEY={api_key}\n')
        print("âœ… API Key å·²å„²å­˜åˆ° .env æª”æ¡ˆ")
        return True
    except Exception as e:
        print(f"å„²å­˜ API Key æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def get_api_key():
    """å–å¾— API Keyï¼Œæä¾›å¤šç¨®å®‰å…¨æ–¹å¼"""
    # å˜—è©¦å¾ .env æª”æ¡ˆè¼‰å…¥
    api_key = load_api_key()
    if api_key:
        print("âœ… å¾ .env æª”æ¡ˆè®€å– API Key æˆåŠŸ")
        return api_key
    
    print("\nğŸ”‘ OpenAI API Key è¨­å®š")
    print("è«‹é¸æ“‡è¨­å®šæ–¹å¼:")
    print("1. æ‰‹å‹•è¼¸å…¥ (æ¨è–¦)")
    print("2. ç¨å¾Œè¨­å®šï¼ˆé€€å‡ºï¼‰")
    
    choice = input("è«‹é¸æ“‡ (1-2): ").strip()
    
    if choice == "1":
        print("\nè«‹è¼¸å…¥ä½ çš„ OpenAI API Key:")
        print("ğŸ’¡ æç¤º: è¼¸å…¥æ™‚ä¸æœƒé¡¯ç¤ºå…§å®¹ï¼Œé€™æ˜¯æ­£å¸¸çš„å®‰å…¨æ©Ÿåˆ¶")
        api_key = getpass.getpass("API Key: ").strip()
        
        if api_key and len(api_key) > 20:  # åŸºæœ¬é©—è­‰
            print("æ˜¯å¦è¦å„²å­˜ API Key åˆ° .env æª”æ¡ˆä»¥ä¾¿ä¸‹æ¬¡è‡ªå‹•è®€å…¥ï¼Ÿ\né€™æœƒå°‡ API Key å„²å­˜åœ¨æœ¬æ©Ÿã€æœ¬è·¯å¾‘ä¸‹ï¼Œè«‹å‹¿åˆ†äº«çµ¦ä»–äººã€‚\nä¹Ÿå»ºè­°æ‚¨ä½¿ç”¨ .env æª”æ¡ˆä¾†å„²å­˜ API Keyï¼Œè€Œä¸æ˜¯æ‰‹å‹•è¼¸å…¥ã€‚\nå¼·çƒˆå»ºè­°å®šæœŸæ¸…ç†api keyä»¥é˜²æ´©æ¼ç”¢ç”Ÿä½¿ç”¨è²»ç”¨")
            save_choice = input("æ˜¯å¦å­˜è‡³.envæª”æ¡ˆï¼Ÿ(y/n): ").strip().lower()
            if save_choice == 'y':
                save_api_key(api_key)
            return api_key
        else:
            print("âŒ API Key æ ¼å¼ä¸æ­£ç¢º")
            return None
    
    return None

# === æœ¬åœ° Whisper è½‰éŒ„ ===
def transcribe_local(audio_path, model_size="base", language='zh'):
    """ä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹è½‰éŒ„"""
    try:
        print(f"è¼‰å…¥æœ¬åœ° Whisper æ¨¡å‹: {model_size}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ GPU å¯ç”¨ (Mac M1/M2/M3)
        device = "cpu"
        use_gpu = False
        try:
            import torch
            if torch.backends.mps.is_available():
                # Mac GPU æœ‰ç¨€ç–å¼µé‡é™åˆ¶ï¼Œç›´æ¥ä½¿ç”¨ CPU é¿å…éŒ¯èª¤
                print("âœ… æª¢æ¸¬åˆ° Mac GPU (MPS)ï¼Œä½†ç”±æ–¼ç¨€ç–å¼µé‡é™åˆ¶ï¼Œå¯èƒ½æœƒä½¿ç”¨ CPU ä»¥ç¢ºä¿ç©©å®šæ€§")
                device = "mps"
                use_gpu = True
            elif torch.cuda.is_available():
                device = "cuda"
                use_gpu = True
                print("âœ… æª¢æ¸¬åˆ° CUDA GPUï¼Œå°‡ä½¿ç”¨ GPU åŠ é€Ÿ")
            else:
                print("âš ï¸  æœªæª¢æ¸¬åˆ° GPUï¼Œä½¿ç”¨ CPU")
        except ImportError:
            print("âš ï¸  PyTorch æœªå®‰è£ï¼Œä½¿ç”¨ CPU")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ‰“åŒ…ç’°å¢ƒ
        import sys
        is_packaged = getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS')
        
        if is_packaged:
            print("ğŸ“¦ æª¢æ¸¬åˆ°æ‰“åŒ…ç’°å¢ƒï¼Œä½¿ç”¨ç‰¹æ®Šè™•ç†")
            # åœ¨æ‰“åŒ…ç’°å¢ƒä¸­ï¼Œéœ€è¦æ‰‹å‹•è¨­å®š Whisper è³‡æºè·¯å¾‘
            try:
                import os
                # è¨­å®š Whisper è³‡æºç›®éŒ„
                model_dir = os.path.join(os.path.expanduser("~"), ".cache", "whisper")
                os.makedirs(model_dir, exist_ok=True)
                # è¨­å®šç’°å¢ƒè®Šæ•¸
                os.environ['WHISPER_CACHE_DIR'] = model_dir
                print(f"è¨­å®š Whisper å¿«å–ç›®éŒ„: {model_dir}")
            except Exception as e:
                print(f"âš ï¸  è¨­å®š Whisper è³‡æºè·¯å¾‘æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # å˜—è©¦è¼‰å…¥æ¨¡å‹ä¸¦è™•ç†å„ç¨®éŒ¯èª¤
        try:
            model = whisper.load_model(model_size, device=device)
            print(f"é–‹å§‹è½‰éŒ„ (èªè¨€: {language}, è¨­å‚™: {device})...")
        except Exception as model_error:
            error_msg = str(model_error).lower()
            
            if "sparse" in error_msg or "mps" in error_msg:
                print("âŒ Mac GPU é‡åˆ°ç¨€ç–å¼µé‡é™åˆ¶ï¼Œé™ç´šåˆ° CPU")
                device = "cpu"
                model = whisper.load_model(model_size, device=device)
                use_gpu = False
                print(f"é–‹å§‹è½‰éŒ„ (èªè¨€: {language}, è¨­å‚™: {device})...")
            elif "mel_filters" in error_msg or "assets" in error_msg:
                print("âŒ Whisper è³‡æºæª”æ¡ˆç¼ºå¤±ï¼Œå˜—è©¦é‡æ–°ä¸‹è¼‰...")
                # å˜—è©¦æ¸…ç†å¿«å–ä¸¦é‡æ–°ä¸‹è¼‰
                try:
                    import shutil
                    import os
                    cache_dir = os.path.expanduser("~/.cache/whisper")
                    if os.path.exists(cache_dir):
                        shutil.rmtree(cache_dir)
                        print("æ¸…ç† Whisper å¿«å–å®Œæˆ")
                except Exception as cleanup_error:
                    print(f"æ¸…ç†å¿«å–æ™‚ç™¼ç”ŸéŒ¯èª¤: {cleanup_error}")
                
                # é‡æ–°è¼‰å…¥æ¨¡å‹
                model = whisper.load_model(model_size, device=device)
                print(f"é–‹å§‹è½‰éŒ„ (èªè¨€: {language}, è¨­å‚™: {device})...")
            else:
                raise model_error
        
        # æ ¹æ“šè¨­å‚™è¨­å®šè½‰éŒ„åƒæ•¸
        transcribe_kwargs = {
            'language': language, 
            'verbose': True, 
            'word_timestamps': True
        }
        
        # åªåœ¨æ”¯æ´çš„ GPU ä¸Šå•Ÿç”¨ FP16
        if use_gpu and device == "cuda":
            transcribe_kwargs['fp16'] = True  # åªæœ‰ CUDA å®Œå…¨æ”¯æ´ FP16
        elif use_gpu and device == "mps":
            # Mac GPU ä¸ä½¿ç”¨ FP16 é¿å…ç¨€ç–å¼µé‡å•é¡Œ
            print("âš ï¸  Mac GPU ä¸ä½¿ç”¨ FP16 ä»¥é¿å…ç¨€ç–å¼µé‡éŒ¯èª¤")
            
        result = model.transcribe(audio_path, **transcribe_kwargs)
        return result
    except Exception as e:
        print(f"æœ¬åœ°è½‰éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === API Whisper è½‰éŒ„ ===
def transcribe_api(audio_file_path, client=None, language=None):
    """ä½¿ç”¨ OpenAI Whisper API è½‰éŒ„"""
    try:
        with open(audio_file_path, "rb") as audio_file:
            if client is None:
                client = openai.OpenAI()
            response = client.audio.transcriptions.create(
                model="whisper-1",
                language=language,
                file=audio_file
            )
            return response.text
    except Exception as e:
        print(f"API è½‰éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === GPT æ¨™é»ç¬¦è™Ÿè™•ç† ===
def add_punctuation_with_gpt(text_chunk, client):
    """ä½¿ç”¨ GPT ç‚ºæ–‡å­—ç‰‡æ®µæ·»åŠ æ¨™é»ç¬¦è™Ÿ"""
    try:
        max_retry = 3
        for attempt in range(max_retry):
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ–‡å­—ç·¨è¼¯åŠ©æ‰‹ã€‚è«‹ç‚ºä»¥ä¸‹æ²’æœ‰æ¨™é»ç¬¦è™Ÿçš„æ–‡å­—æ·»åŠ é©ç•¶çš„æ¨™é»ç¬¦è™Ÿï¼ŒåŒ…æ‹¬å¥è™Ÿã€é€—è™Ÿã€å•è™Ÿã€é©šå˜†è™Ÿç­‰ã€‚ä¿æŒåŸæ–‡çš„èªæ„å’Œçµæ§‹ï¼Œåªæ·»åŠ æ¨™é»ç¬¦è™Ÿã€‚"
                    },
                    {
                        "role": "user", 
                        "content": f"è«‹ç‚ºä»¥ä¸‹æ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼š\n{text_chunk}"
                    }
                ],
                max_tokens=len(text_chunk)+500,
                temperature=0.1
            )
            result = response.choices[0].message.content.strip()
            len_orig = len(text_chunk)
            len_result = len(result)
            if len_orig == 0:
                break
            diff = abs(len_result - len_orig) / len_orig
            if diff <= 0.2 or attempt == max_retry - 1:
                print(f"âœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
                print(f"è™•ç†å‰æ–‡å­—é•·åº¦: {len_orig} å­—å…ƒ")
                print(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(result)} å­—å…ƒ")
                return result
            # å¦å‰‡é‡è©¦
    except Exception as e:
        print(f"GPT æ¨™é»ç¬¦è™Ÿè™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return text_chunk  # å¦‚æœå¤±æ•—ï¼Œè¿”å›åŸæ–‡

# === æ‰¹é‡æ¨™é»ç¬¦è™Ÿè™•ç† ===
def process_text_with_punctuation(text, client, text_len=1000):
    """å°‡æ–‡å­—åˆ†å‰²æˆç‰‡æ®µï¼Œæ‰¹é‡è™•ç†æ¨™é»ç¬¦è™Ÿ"""
    print(f"\nğŸ“ é–‹å§‹æ¨™é»ç¬¦è™Ÿè™•ç†...")
    print(f"åŸå§‹æ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
    
    # ç°¡å–®æŒ‰å­—å…ƒæ•¸åˆ†å‰²ï¼Œé¿å…è¤‡é›œçš„è©èªåˆ†å‰²é‚è¼¯
    chunks = []
    for i in range(0, len(text), text_len):
        chunk = text[i:i + text_len]
        chunks.append(chunk)
    
    print(f"åˆ†å‰²æˆ {len(chunks)} å€‹ç‰‡æ®µ")
    
    processed_chunks = []
    for i, chunk in enumerate(chunks, 1):
        print(f"--- è™•ç†ç‰‡æ®µ {i}/{len(chunks)} ({len(chunk)} å­—å…ƒ)...")
        
        punctuated_chunk = add_punctuation_with_gpt(chunk, client)
        processed_chunks.append(punctuated_chunk)
        
        # é¿å… API é™åˆ¶
        if i < len(chunks):
            time.sleep(0.5)
    
    # åˆä½µæ‰€æœ‰è™•ç†éçš„ç‰‡æ®µ
    final_text = "".join(processed_chunks)
    print(f"âœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
    print(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(final_text)} å­—å…ƒ")
    
    return final_text

# === æ¸…ç©ºé å­˜æ¨¡å‹ ===
def clear_whisper_models():
    """æ¸…ç©ºç›®å‰å·²å­˜é å­˜æ¨¡å‹"""
    try:
        import shutil
        import os
        
        # Whisper æ¨¡å‹å¿«å–ç›®éŒ„
        cache_dir = os.path.expanduser("~/.cache/whisper")
        
        if not os.path.exists(cache_dir):
            print("âœ… æ²’æœ‰æ‰¾åˆ° Whisper æ¨¡å‹å¿«å–ç›®éŒ„")
            print("å¯èƒ½åŸå› ï¼š")
            print("1. å°šæœªä¸‹è¼‰éä»»ä½• Whisper æ¨¡å‹")
            print("2. æ¨¡å‹å„²å­˜åœ¨å…¶ä»–ä½ç½®")
            return True
        
        # æª¢æŸ¥ç›®éŒ„å…§å®¹
        files = os.listdir(cache_dir)
        if not files:
            print("âœ… Whisper å¿«å–ç›®éŒ„ç‚ºç©ºï¼Œç„¡éœ€æ¸…ç†")
            return True
        
        print(f"ğŸ“ æ‰¾åˆ° Whisper å¿«å–ç›®éŒ„: {cache_dir}")
        print(f"ğŸ“Š ç›®éŒ„ä¸­åŒ…å« {len(files)} å€‹æª”æ¡ˆ/è³‡æ–™å¤¾")
        
        # é¡¯ç¤ºå°‡è¦åˆªé™¤çš„å…§å®¹
        print("\nå°‡è¦åˆªé™¤çš„å…§å®¹:")
        for file in files:
            file_path = os.path.join(cache_dir, file)
            if os.path.isdir(file_path):
                print(f"  ğŸ“ {file}/")
            else:
                size = os.path.getsize(file_path)
                size_mb = size / (1024 * 1024)
                print(f"  ğŸ“„ {file} ({size_mb:.1f} MB)")
        
        # ç¢ºèªåˆªé™¤
        print(f"\nâš ï¸  é€™å°‡åˆªé™¤æ‰€æœ‰ Whisper æ¨¡å‹æª”æ¡ˆï¼Œé‡‹æ”¾ç£ç¢Ÿç©ºé–“")
        print("ä¸‹æ¬¡ä½¿ç”¨æ™‚éœ€è¦é‡æ–°ä¸‹è¼‰æ¨¡å‹")
        confirm = input("ç¢ºå®šè¦æ¸…ç©ºæ‰€æœ‰é å­˜æ¨¡å‹å—ï¼Ÿ(y/n): ").strip().lower()
        
        if confirm == 'y':
            # åˆªé™¤æ•´å€‹å¿«å–ç›®éŒ„
            shutil.rmtree(cache_dir)
            print("âœ… Whisper æ¨¡å‹å¿«å–å·²æ¸…ç©º")
            print("ğŸ’¡ ä¸‹æ¬¡ä½¿ç”¨æ™‚æœƒè‡ªå‹•é‡æ–°ä¸‹è¼‰æ‰€éœ€çš„æ¨¡å‹")
            return True
        else:
            print("âŒ å–æ¶ˆæ¸…ç©ºæ“ä½œ")
            return False
            
    except Exception as e:
        print(f"âŒ æ¸…ç©ºæ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

# === æ™ºèƒ½æ¨¡å‹é¸æ“‡ ===
def smart_model_selection(audio_path, language = None):
    """æ™ºèƒ½é¸æ“‡æœ€ä½³æ¨¡å‹"""
    print("\nğŸ¤– æ™ºèƒ½æ¨¡å‹é¸æ“‡æ¨¡å¼")
    
    # æª¢æŸ¥éŸ³è¨Šé•·åº¦
    try:
        audio = AudioSegment.from_file(audio_path)
        duration_minutes = len(audio) / (1000 * 60)
        print(f"éŸ³è¨Šé•·åº¦: {duration_minutes:.1f} åˆ†é˜")
    except:
        duration_minutes = 0
    
    
    model_order = ["large-v3", "large-v2", "large", "medium", "small", "base", "tiny"]
    
    recommended = check_system_resources()
    
    print(f"ç³»çµ±å»ºè­°æ¨¡å‹: {recommended}")
    print("å°‡å¾å»ºè­°æ¨¡å‹é–‹å§‹å˜—è©¦ï¼Œå¦‚æœå¤±æ•—æœƒè‡ªå‹•é™ç´š...")
    
    for model_size in model_order:
        print(f"\nå˜—è©¦ä½¿ç”¨ {model_size} æ¨¡å‹...")
        try:
            result = transcribe_local(audio_path, model_size, language)
            if result:
                print(f"âœ… {model_size} æ¨¡å‹è½‰éŒ„æˆåŠŸï¼")
                return result, model_size
            else:
                print(f"âŒ {model_size} æ¨¡å‹è½‰éŒ„å¤±æ•—")
        except Exception as e:
            print(f"âŒ {model_size} æ¨¡å‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            if "out of memory" in str(e).lower() or "cuda" in str(e).lower():
                print("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ä¸è¶³ï¼Œå˜—è©¦è¼ƒå°æ¨¡å‹...")
                continue
            else:
                print("å…¶ä»–éŒ¯èª¤ï¼Œå˜—è©¦è¼ƒå°æ¨¡å‹...")
                continue
    
    print("âŒ æ‰€æœ‰æœ¬åœ°æ¨¡å‹éƒ½å¤±æ•—äº†")
    return None, None

# === å–å¾—å½±ç‰‡è³‡è¨Š ===
def get_video_info(youtube_url):
    """å–å¾— YouTube å½±ç‰‡è³‡è¨Šè€Œä¸ä¸‹è¼‰"""
    try:
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print(f"æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š: {youtube_url}")
            info = ydl.extract_info(youtube_url, download=False)
            title = info.get('title', 'unknown')
            duration = info.get('duration', 0)
            uploader = info.get('uploader', 'unknown')
            
            return {
                'title': title,
                'duration': duration,
                'uploader': uploader,
                'url': youtube_url
            }
    except Exception as e:
        print(f"å–å¾—å½±ç‰‡è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# === è™•ç†æœ¬åœ°éŸ³è¨Šæ–‡ä»¶ ===
def process_local_audio(file_path):
    """è™•ç†æœ¬åœ°éŸ³è¨Šæ–‡ä»¶ï¼Œè½‰æ›ç‚ºé©åˆè½‰éŒ„çš„æ ¼å¼"""
    try:
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.isfile(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None, None
        
        # ç²å–æ–‡ä»¶ä¿¡æ¯
        file_name = os.path.splitext(os.path.basename(file_path))[0]
        file_ext = os.path.splitext(file_path)[1].lower()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºéŸ³è¨Šæ–‡ä»¶
        audio_extensions = ['.mp3', '.wav', '.m4a', '.aac', '.flac', '.ogg', '.wma']
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
        
        if file_ext in audio_extensions:
            print(f"âœ… æª¢æ¸¬åˆ°éŸ³è¨Šæ–‡ä»¶: {file_path}")
            return file_path, file_name
        elif file_ext in video_extensions:
            print(f"ğŸ“¹ æª¢æ¸¬åˆ°å½±ç‰‡æ–‡ä»¶: {file_path}")
            print("å°‡ç›´æ¥ä½¿ç”¨æ­¤æ–‡ä»¶é€²è¡Œè½‰éŒ„...")
            return file_path, file_name
        else:
            print(f"âš ï¸  æœªçŸ¥æ–‡ä»¶æ ¼å¼: {file_ext}")
            print("å˜—è©¦ç›´æ¥ä½¿ç”¨æ­¤æ–‡ä»¶...")
            return file_path, file_name
            
    except Exception as e:
        print(f"è™•ç†æœ¬åœ°æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None

# === ä¸‹è¼‰ YouTube éŸ³è¨Š ===
def download_audio(youtube_url, audio_path="downloads"):
    """ä¸‹è¼‰ YouTube éŸ³è¨Šæª”æ¡ˆ"""
    try:
        if not os.path.exists(audio_path):
            os.makedirs(audio_path)
        
        # å…ˆå–å¾—å½±ç‰‡è³‡è¨Šä»¥ç²å–æ¨™é¡Œ
        ydl_info_opts = {
            'quiet': True,
            'no_warnings': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_info_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=False)
            title = info.get('title', 'unknown')
            clean_title = clean_filename(title)
        
        # æª¢æŸ¥æ˜¯å¦ç‚º HLS ä¸²æµ
        is_hls = '.m3u8' in youtube_url.lower()
        
        if is_hls:
            # HLS ä¸²æµä½¿ç”¨ä¸åŒçš„è¨­å®š
            ydl_opts = {
                'format': 'best',
                'outtmpl': os.path.join(audio_path, f'{clean_title}.%(ext)s'),
                'noplaylist': True,
                'ignoreerrors': True,
                'no_warnings': True,
            }
        else:
            # ä¸€èˆ¬å½±ç‰‡ä½¿ç”¨éŸ³è¨Šæå–
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': os.path.join(audio_path, f'{clean_title}.%(ext)s'),
                'extractaudio': True,
                'audioformat': 'mp3',
                'noplaylist': True,
                'ignoreerrors': True,
                'no_warnings': True,
            }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print(f"æ­£åœ¨ä¸‹è¼‰éŸ³è¨Š: {youtube_url}")
            print(f"åŸå§‹æ¨™é¡Œ: {title}")
            print(f"æ¸…ç†å¾Œæ¨™é¡Œ: {clean_title}")
            ydl.download([youtube_url])
            
            # å°‹æ‰¾ä¸‹è¼‰çš„æª”æ¡ˆ - æ”¯æ´å¤šç¨®å¯èƒ½çš„æª”æ¡ˆåç¨±
            downloaded_files = []
            import time
            current_time = time.time()
            
            for file in os.listdir(audio_path):
                file_path = os.path.join(audio_path, file)
                # æª¢æŸ¥æ˜¯å¦ç‚ºéŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ
                if file.endswith(('.mp3', '.m4a', '.webm', '.ogg', '.mp4', '.avi', '.mov', '.mkv', '.ts')):
                    # æª¢æŸ¥æª”æ¡ˆä¿®æ”¹æ™‚é–“ï¼ˆæœ€è¿‘ä¸‹è¼‰çš„ï¼‰
                    file_time = os.path.getmtime(file_path)
                    # å¦‚æœæª”æ¡ˆæ˜¯åœ¨æœ€è¿‘5åˆ†é˜å…§å‰µå»ºçš„ï¼Œèªç‚ºæ˜¯å‰›ä¸‹è¼‰çš„
                    if current_time - file_time < 300:  # 5åˆ†é˜
                        downloaded_files.append((file_path, file_time, file))
            
            if downloaded_files:
                # é¸æ“‡æœ€æ–°çš„æª”æ¡ˆ
                latest_file = max(downloaded_files, key=lambda x: x[1])
                file_path, _, file_name = latest_file
                print(f"éŸ³è¨Šä¸‹è¼‰å®Œæˆ: {file_name}")
                return file_path, clean_title
            
            # å¦‚æœæ‰¾ä¸åˆ°æœ€è¿‘ä¸‹è¼‰çš„æª”æ¡ˆï¼Œå˜—è©¦å°‹æ‰¾ä»»ä½•éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ
            print("æœªæ‰¾åˆ°æœ€è¿‘ä¸‹è¼‰çš„æª”æ¡ˆï¼Œæœå°‹æ‰€æœ‰éŸ³è¨Š/å½±ç‰‡æª”æ¡ˆ...")
            all_media_files = []
            for file in os.listdir(audio_path):
                if file.endswith(('.mp3', '.m4a', '.webm', '.ogg', '.mp4', '.avi', '.mov', '.mkv', '.ts')):
                    file_path = os.path.join(audio_path, file)
                    file_time = os.path.getmtime(file_path)
                    all_media_files.append((file_path, file_time, file))
            
            if all_media_files:
                # é¸æ“‡æœ€æ–°çš„æª”æ¡ˆ
                latest_file = max(all_media_files, key=lambda x: x[1])
                file_path, _, file_name = latest_file
                print(f"æ‰¾åˆ°åª’é«”æª”æ¡ˆ: {file_name}")
                return file_path, clean_title
            
            raise Exception("æ‰¾ä¸åˆ°ä¸‹è¼‰çš„éŸ³è¨Šæª”æ¡ˆ")
        
    except Exception as e:
        print(f"ä¸‹è¼‰éŸ³è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None

# === è™•ç†ä¸åŒé¡å‹çš„å½±ç‰‡ä¾†æº ===
def process_video_source(source):
    """è™•ç†ä¸åŒé¡å‹çš„å½±ç‰‡ä¾†æº"""
    source = source.strip()
    
    # æª¢æŸ¥æ˜¯å¦ç‚º blob URL
    if source.startswith('blob:'):
        print("\nâš ï¸  æª¢æ¸¬åˆ° Blob URL")
        print("Blob URL ç„¡æ³•ç›´æ¥ä¸‹è¼‰ï¼Œå› ç‚ºå®ƒæ˜¯ç€è¦½å™¨å…§éƒ¨çš„è‡¨æ™‚å¼•ç”¨ã€‚")
        print("\nè«‹å˜—è©¦ä»¥ä¸‹æ–¹æ³•ï¼š")
        print("1. åœ¨ç€è¦½å™¨ä¸­æŒ‰ F12 æ‰“é–‹é–‹ç™¼è€…å·¥å…·")
        print("2. åˆ‡æ›åˆ° Network æ¨™ç±¤")
        print("3. é‡æ–°è¼‰å…¥é é¢æˆ–æ’­æ”¾å½±ç‰‡")
        print("4. å°‹æ‰¾å¯¦éš›çš„å½±ç‰‡æ–‡ä»¶ URLï¼ˆ.mp4, .m3u8, .ts ç­‰ï¼‰")
        print("5. è¤‡è£½è©² URL ä¸¦é‡æ–°è¼¸å…¥")
        return None, None, "blob_url"
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºæœ¬åœ°æ–‡ä»¶
    elif os.path.isfile(source):
        print(f"\nğŸ“ æª¢æ¸¬åˆ°æœ¬åœ°æ–‡ä»¶: {source}")
        return source, os.path.splitext(os.path.basename(source))[0], "local_file"
    
    # æª¢æŸ¥æ˜¯å¦ç‚º YouTube URL
    elif 'youtube.com' in source or 'youtu.be' in source:
        return source, None, "youtube"
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºå…¶ä»–ç·šä¸Šå½±ç‰‡ URL
    elif source.startswith(('http://', 'https://')):
        print(f"\nğŸŒ æª¢æ¸¬åˆ°ç·šä¸Šå½±ç‰‡ URL: {source}")
        print("å˜—è©¦ä½¿ç”¨ yt-dlp ä¸‹è¼‰...")
        return source, None, "online_video"
    
    else:
        print(f"\nâŒ ç„¡æ³•è­˜åˆ¥çš„ä¾†æºæ ¼å¼: {source}")
        return None, None, "unknown"

# === ç‚ºç‰¹å®šè·¯å¾‘çš„é€å­—ç¨¿åŠ ä¸Šæ¨™é»ç¬¦è™Ÿ ===
def add_punctuation_to_file(file_path):
    """ç‚ºæŒ‡å®šè·¯å¾‘çš„é€å­—ç¨¿æ–‡ä»¶åŠ ä¸Šæ¨™é»ç¬¦è™Ÿ"""
    try:
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.isfile(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        
        # è®€å–æ–‡ä»¶å…§å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        if not content:
            print("âŒ æ–‡ä»¶ç‚ºç©º")
            return False
        
        print(f"ğŸ“„ è®€å–æ–‡ä»¶: {file_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {len(content)} å­—å…ƒ")
        
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰æ¨™é»ç¬¦è™Ÿ
        has_punctuation = any(p in content for p in 'ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼š')
        if has_punctuation:
            print("âš ï¸  æ–‡ä»¶ä¼¼ä¹å·²ç¶“åŒ…å«æ¨™é»ç¬¦è™Ÿ")
            overwrite = input("æ˜¯å¦è¦é‡æ–°è™•ç†ï¼Ÿ(y/n): ").strip().lower()
            if overwrite != 'y':
                print("âŒ å–æ¶ˆè™•ç†")
                return False
        
        # è¨ˆç®—é ä¼°è²»ç”¨
        text_length = len(content)
        estimated_tokens = text_length * 1.3  # ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦ç´„1.3å€‹token
        estimated_cost = (estimated_tokens / 1000) * 0.00015  # GPT-4o-mini åƒ¹æ ¼ï¼š$0.00015/1K tokens
        
        print(f"\nğŸ’° è²»ç”¨é ä¼°:")
        print(f"   æ–‡å­—é•·åº¦: {text_length} å­—å…ƒ")
        print(f"   é ä¼° tokens: {estimated_tokens:.0f}")
        print(f"   é ä¼°è²»ç”¨: ç´„ ${estimated_cost:.4f} ç¾å…ƒ (ç´„ {estimated_cost * 30:.2f} å°å¹£)")
        
        # ç¢ºèªæ˜¯å¦ç¹¼çºŒè™•ç†
        print(f"\næ˜¯å¦è¦ç¹¼çºŒé€²è¡Œæ¨™é»ç¬¦è™Ÿè™•ç†ï¼Ÿ")
        print("1. æ˜¯ï¼Œç¹¼çºŒè™•ç†")
        print("2. å¦ï¼Œå–æ¶ˆè™•ç†")
        
        confirm = input("è«‹é¸æ“‡ (1-2): ").strip()
        if confirm != "1":
            print("âŒ å–æ¶ˆè™•ç†")
            return False
        
        # å–å¾— API Key
        api_key = get_api_key()
        if not api_key:
            print("âŒ ç„¡æ³•å–å¾— API Keyï¼Œç„¡æ³•é€²è¡Œæ¨™é»ç¬¦è™Ÿè™•ç†")
            return False
        
        # å‚™ä»½åŸæ–‡ä»¶
        backup_path = file_path + ".backup"
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ’¾ å·²å‚™ä»½åŸæ–‡ä»¶è‡³: {backup_path}")
        
        # è™•ç†æ¨™é»ç¬¦è™Ÿ
        client = openai.OpenAI(api_key=api_key)
        punctuated_text = process_text_with_punctuation(content, client)
        
        # å„²å­˜è™•ç†å¾Œçš„æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(punctuated_text)
        
        print(f"âœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
        print(f"ğŸ“„ å·²æ›´æ–°æ–‡ä»¶: {file_path}")
        print(f"ğŸ“Š è™•ç†å¾Œé•·åº¦: {len(punctuated_text)} å­—å…ƒ")
        print(f"ğŸ’¾ åŸæ–‡ä»¶å‚™ä»½: {backup_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è™•ç†æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def save_file(used_method, output_filename, text):
    with open(output_filename, "w", encoding="utf-8") as f:
        f.write(text)
    
    print(f"\nâœ… æ¨™é»ç¬¦è™Ÿè™•ç†å®Œæˆï¼")
    print(f"ä½¿ç”¨æ–¹æ³•: {used_method} + GPTæ¨™é»ç¬¦è™Ÿè™•ç†")
    print(f"è¼¸å‡ºæª”æ¡ˆ: {output_filename}")
    print(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")

# === ä¸»ç¨‹å¼ ===
if __name__ == "__main__":
    print("ğŸµ æ™ºèƒ½èªéŸ³è½‰æ–‡å­—å·¥å…·")
    print("=" * 50)
    
    # åŠŸèƒ½é¸æ“‡
    print("è«‹é¸æ“‡åŠŸèƒ½:")
    print("1. è½‰éŒ„å½±ç‰‡ (æ”¯æ´ YouTubeã€æœ¬åœ°æ–‡ä»¶ã€ç·šä¸Šå½±ç‰‡)")
    print("2. ç‚ºç‰¹å®šçš„é€å­—ç¨¿åŠ ä¸Šæ¨™é»ç¬¦è™Ÿ")
    print("3. æ¸…ç©ºç›®å‰å·²å­˜çš„ AI æ¨¡å‹")
    print("4. é€€å‡ºç¨‹å¼")
    choice = input("è«‹é¸æ“‡ (1-4): ").strip()
    
    if choice == "2":
        # ç‚ºç‰¹å®šè·¯å¾‘çš„é€å­—ç¨¿åŠ ä¸Šæ¨™é»ç¬¦è™Ÿ
        print("\nğŸ“ ç‚ºé€å­—ç¨¿åŠ ä¸Šæ¨™é»ç¬¦è™ŸåŠŸèƒ½")
        print("=" * 50)
        
        # å–å¾—æ–‡ä»¶è·¯å¾‘
        print("è«‹è¼¸å…¥è¦è™•ç†çš„é€å­—ç¨¿æ–‡ä»¶è·¯å¾‘:")
        print("æ”¯æ´æ ¼å¼: .txt æ–‡ä»¶")
        print("ç¯„ä¾‹: /path/to/transcript.txt æˆ– output/é€å­—ç¨¿.txt")
        
        file_path = input("æ–‡ä»¶è·¯å¾‘: ").strip()
        if not file_path:
            print("âŒ æœªæä¾›æ–‡ä»¶è·¯å¾‘")
            exit(1)
        
        # è™•ç†æ–‡ä»¶
        success = add_punctuation_to_file(file_path)
        if success:
            print("\nâœ… è™•ç†å®Œæˆï¼")
        else:
            print("\nâŒ è™•ç†å¤±æ•—")
        
        exit(0)
        
    elif choice == "3":
        # æ¸…ç©ºé å­˜æ¨¡å‹
        print("\nğŸ—‘ï¸  æ¸…ç©ºé å­˜ AI æ¨¡å‹åŠŸèƒ½")
        print("=" * 50)
        clear_whisper_models()
        exit(0)
    elif choice == "4":
        print("ç¨‹å¼çµæŸ")
        exit(0)
    elif choice != "1":
        print("ç„¡æ•ˆé¸æ“‡ï¼Œç¨‹å¼çµæŸ")
        exit(1)
    
    # å–å¾—å½±ç‰‡ä¾†æº
    print("\nè«‹è¼¸å…¥å½±ç‰‡ä¾†æº:")
    print("æ”¯æ´æ ¼å¼:")
    print("- YouTube URL (å¦‚: https://www.youtube.com/watch?v=...)")
    print("- æœ¬åœ°æ–‡ä»¶è·¯å¾‘ (å¦‚: /path/to/video.mp4)")
    print("- ç·šä¸Šå½±ç‰‡ URL (å¦‚: https://example.com/video.mp4)")
    print("- æ³¨æ„: Blob URL ç„¡æ³•ç›´æ¥è™•ç†ï¼Œéœ€è¦æ‰¾åˆ°å¯¦éš›çš„å½±ç‰‡ URL")
    
    video_source = input("å½±ç‰‡ä¾†æº: ").strip()
    if not video_source:
        print("æœªæä¾›ä¾†æºï¼Œç¨‹å¼çµæŸ")
        exit(1)
    
    # è™•ç†ä¸åŒé¡å‹çš„å½±ç‰‡ä¾†æº
    processed_source, video_title, source_type = process_video_source(video_source)
    
    if source_type == "blob_url":
        print("\nè«‹æŒ‰ç…§ä¸Šè¿°èªªæ˜æ‰¾åˆ°å¯¦éš›çš„å½±ç‰‡ URL å¾Œé‡æ–°åŸ·è¡Œç¨‹å¼")
        exit(1)
    elif source_type == "unknown":
        print("ç„¡æ³•è™•ç†æ­¤ä¾†æºæ ¼å¼")
        exit(1)
    
    # æ ¹æ“šä¾†æºé¡å‹è™•ç†å½±ç‰‡è³‡è¨Š
    video_info = None
    audio_file = None
    
    if source_type == "local_file":
        # æœ¬åœ°æ–‡ä»¶è™•ç†
        print(f"\nğŸ“ è™•ç†æœ¬åœ°æ–‡ä»¶: {processed_source}")
        audio_file, file_title = process_local_audio(processed_source)
        if not audio_file:
            print("âŒ ç„¡æ³•è™•ç†æœ¬åœ°æ–‡ä»¶")
            exit(1)
        video_title = file_title or "local_video"
        video_info = {'title': video_title, 'duration': 0, 'uploader': 'local', 'url': processed_source}
        
    elif source_type in ["youtube", "online_video"]:
        # ç·šä¸Šå½±ç‰‡è™•ç†
        print("\nğŸ“‹ æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š...")
        video_info = get_video_info(processed_source)
        
        if not video_info:
            print("âŒ ç„¡æ³•å–å¾—å½±ç‰‡è³‡è¨Šï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
            exit(1)
    
    # é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
    if video_info:
        print("\n" + "="*60)
        print("ğŸ“º å½±ç‰‡è³‡è¨Šç¢ºèª")
        print("="*60)
        print(f"æ¨™é¡Œ: {video_info['title']}")
        print(f"ä¸Šå‚³è€…: {video_info['uploader']}")
        if video_info['duration'] > 0:
            duration_minutes = video_info['duration'] / 60
            print(f"é•·åº¦: {duration_minutes:.1f} åˆ†é˜")
        print(f"ä¾†æº: {video_info['url']}")
        print("="*60)
    
    # è®“ä½¿ç”¨è€…ç¢ºèª
    print("\nè«‹ç¢ºèªæ˜¯å¦è¦è½‰éŒ„æ­¤å½±ç‰‡ï¼Ÿ")
    print("1. æ˜¯ï¼Œç¹¼çºŒè½‰éŒ„")
    print("2. å¦ï¼Œé‡æ–°è¼¸å…¥ç¶²å€")
    print("3. é€€å‡ºç¨‹å¼")
    
    confirm = input("è«‹é¸æ“‡ (1-3): ").strip()
    
    if confirm == "2":
        # é‡æ–°è¼¸å…¥ä¾†æº
        video_source = input("\nè«‹é‡æ–°è¼¸å…¥å½±ç‰‡ä¾†æº: ").strip()
        if not video_source:
            print("æœªæä¾›ä¾†æºï¼Œç¨‹å¼çµæŸ")
            exit(1)
        
        # é‡æ–°è™•ç†å½±ç‰‡ä¾†æº
        processed_source, video_title, source_type = process_video_source(video_source)
        
        if source_type == "blob_url":
            print("\nè«‹æŒ‰ç…§ä¸Šè¿°èªªæ˜æ‰¾åˆ°å¯¦éš›çš„å½±ç‰‡ URL å¾Œé‡æ–°åŸ·è¡Œç¨‹å¼")
            exit(1)
        elif source_type == "unknown":
            print("ç„¡æ³•è™•ç†æ­¤ä¾†æºæ ¼å¼")
            exit(1)
        
        # é‡æ–°å–å¾—å½±ç‰‡è³‡è¨Š
        if source_type == "local_file":
            audio_file, file_title = process_local_audio(processed_source)
            if not audio_file:
                print("âŒ ç„¡æ³•è™•ç†æœ¬åœ°æ–‡ä»¶")
                exit(1)
            video_title = file_title or "local_video"
            video_info = {'title': video_title, 'duration': 0, 'uploader': 'local', 'url': processed_source}
        else:
            print("\nğŸ“‹ æ­£åœ¨å–å¾—å½±ç‰‡è³‡è¨Š...")
            video_info = get_video_info(processed_source)
            
            if not video_info:
                print("âŒ ç„¡æ³•å–å¾—å½±ç‰‡è³‡è¨Šï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
                exit(1)
        
        # å†æ¬¡é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
        print("\n" + "="*60)
        print("ğŸ“º å½±ç‰‡è³‡è¨Šç¢ºèª")
        print("="*60)
        print(f"æ¨™é¡Œ: {video_info['title']}")
        print(f"ä¸Šå‚³è€…: {video_info['uploader']}")
        if video_info['duration'] > 0:
            duration_minutes = video_info['duration'] / 60
            print(f"é•·åº¦: {duration_minutes:.1f} åˆ†é˜")
        print(f"ä¾†æº: {video_info['url']}")
        print("="*60)
        
        # å†æ¬¡ç¢ºèª
        confirm = input("\nç¢ºèªè½‰éŒ„æ­¤å½±ç‰‡ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("ç¨‹å¼çµæŸ")
            exit(1)
            
    elif confirm == "3":
        print("ç¨‹å¼çµæŸ")
        exit(1)
    elif confirm != "1":
        print("ç„¡æ•ˆé¸æ“‡ï¼Œç¨‹å¼çµæŸ")
        exit(1)
    
    # é¸æ“‡è½‰éŒ„èªè¨€
    print("\nè«‹é¸æ“‡è½‰éŒ„èªè¨€:")
    print("1. ä¸­æ–‡")
    print("2. è‹±æ–‡")
    print("3. å¤šèªè¨€æ··é›œ")
    language = input("è«‹é¸æ“‡ (1-3): ").strip()
    
    if language == '1':
        language = 'zh'
    elif language == '2':
        language = 'en'
    else:
        language = None
    
    # é¸æ“‡è½‰éŒ„æ–¹å¼
    print("\nè«‹é¸æ“‡è½‰éŒ„æ–¹å¼:")
    print("1. æ™ºèƒ½æ¨¡å¼ (ç”±å¤§è‡³å°æ¸¬è©¦æœ¬åœ°å¯ç”¨çš„æ¨¡å‹)")
    print("2. æœ¬åœ°æ¨¡å¼ (åƒ…ä½¿ç”¨æœ¬åœ°æ¨¡å‹)")
    if video_info['duration'] > 0:
        print(f"3. APIæ¨¡å¼ (åƒ…ä½¿ç”¨OpenAI APIï¼Œé ä¼°è™•ç†åƒ¹æ ¼ï¼š{round(0.2*video_info['duration']/60, 2)}å…ƒ)")
    else:
        print("3. APIæ¨¡å¼ (åƒ…ä½¿ç”¨OpenAI APIï¼Œé ä¼°è™•ç†åƒ¹æ ¼ï¼šæœªçŸ¥)")
    
    mode = input("è«‹é¸æ“‡ (1-3): ").strip()
    
    # è™•ç†éŸ³è¨Šæ–‡ä»¶
    if source_type != "local_file":
        # ä¸‹è¼‰éŸ³è¨Š
        print("\né–‹å§‹ä¸‹è¼‰éŸ³è¨Š...")
        max_retries = 3
        
        for attempt in range(max_retries):
            print(f"å˜—è©¦ç¬¬ {attempt + 1} æ¬¡ä¸‹è¼‰...")
            result = download_audio(processed_source)
            if result and result[0]:
                audio_file, video_title = result
                break
            if attempt < max_retries - 1:
                print("ç­‰å¾… 3 ç§’å¾Œé‡è©¦...")
                time.sleep(3)
        
        if not audio_file or not video_title:
            print("âŒ ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²å€æ˜¯å¦æ­£ç¢º")
            exit(1)
        
        print(f"âœ… éŸ³è¨Šä¸‹è¼‰æˆåŠŸ: {video_title}")
    else:
        # æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        video_title = video_info['title']
        print(f"âœ… ä½¿ç”¨æœ¬åœ°æ–‡ä»¶: {video_title}")
    
    # æ ¹æ“šé¸æ“‡çš„æ¨¡å¼é€²è¡Œè½‰éŒ„
    transcript = None
    used_method = ""
    
    if mode == "1":  # æ™ºèƒ½æ¨¡å¼
        print("\nğŸ¤– æ™ºèƒ½æ¨¡å¼å•Ÿå‹•")
        # å…ˆå˜—è©¦æœ¬åœ°
        transcript, model_used = smart_model_selection(audio_file, language)
        if transcript:
            used_method = f"æœ¬åœ°æ¨¡å‹ ({model_used})"
        else:
            print("\næœ¬åœ°è½‰éŒ„å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨ API...")
            api_key = get_api_key()
            if api_key:
                client = openai.OpenAI(api_key=api_key)
                transcript_text = transcribe_api(audio_file, client, language)
                if transcript_text:
                    transcript = {"text": transcript_text}
                    used_method = "OpenAI API"
                else:
                    print("âŒ API è½‰éŒ„ä¹Ÿå¤±æ•—äº†")
            else:
                print("âŒ ç„¡æ³•å–å¾— API Keyï¼Œè½‰éŒ„å¤±æ•—")
    
    elif mode == "2":  # æœ¬åœ°æ¨¡å¼
        print("\nğŸ’» æœ¬åœ°æ¨¡å¼")
        model_size = input("è«‹é¸æ“‡æ¨¡å‹å¤§å° (large-v3/large-v2/large/medium/small/base/tiny), è¶Šå¤§å“è³ªè¶Šå¥½ ä½†ä¹Ÿéœ€è¦æ›´å¤šçš„é‹è¡Œè³‡æºåŠæ™‚é–“, é è¨­\"base\": ").strip() or "base"
        transcript = transcribe_local(audio_file, model_size, language)
        if transcript:
            used_method = f"æœ¬åœ°æ¨¡å‹ ({model_size})"
    
    elif mode == "3":  # APIæ¨¡å¼
        print("\nğŸŒ APIæ¨¡å¼")
        api_key = get_api_key()
        if api_key:
            print("æ­£åœ¨ä½¿ç”¨ API è½‰éŒ„...")
            client = openai.OpenAI(api_key=api_key)
            transcript_text = transcribe_api(audio_file, client, language)
            if transcript_text:
                transcript = {"text": transcript_text}
                used_method = "OpenAI API"
        else:
            print("âŒ ç„¡æ³•å–å¾— API Key")
    
    # å„²å­˜çµæœ
    if transcript:
        output_path = "output"
        if not os.path.exists(output_path):
            os.makedirs(output_path)
        output_filename = os.path.join(output_path, f"{video_title}.txt")
        traditional_text = zhconv.convert(transcript["text"], 'zh-hant')
        punctuation_choice = ''
        if mode != "3": # not using OpenIA API
            # è©¢å•æ˜¯å¦è¦æ·»åŠ æ¨™é»ç¬¦è™Ÿ
            print(f"\nğŸ“ è½‰éŒ„å®Œæˆï¼åŸå§‹æ–‡å­—é•·åº¦: {len(traditional_text)} å­—å…ƒ")
            print("\næ˜¯å¦è¦ä½¿ç”¨ GPT ç‚ºæ–‡å­—æ·»åŠ æ¨™é»ç¬¦è™Ÿï¼Ÿ")
            # è¨ˆç®—æ¨™é»ç¬¦è™Ÿè™•ç†çš„é ä¼°æˆæœ¬
            text_length = len(traditional_text)
            estimated_tokens = text_length * 1.3  # ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦ç´„1.3å€‹token
            estimated_cost = (estimated_tokens / 1000) * 0.00015  # GPT-4o-mini åƒ¹æ ¼ï¼š$0.00015/1K tokens
            
            print("1. æ˜¯ï¼Œæ·»åŠ æ¨™é»ç¬¦è™Ÿ (éœ€è¦ OpenAI API Key)")
            print(f"   é ä¼°æˆæœ¬: ç´„ ${estimated_cost:.4f} ç¾å…ƒ (ç´„ {estimated_cost * 30:.2f} å°å¹£)")
            print(f"   æ–‡å­—é•·åº¦: {text_length} å­—å…ƒï¼Œé ä¼° {estimated_tokens:.0f} tokens")
            print("2. å¦ï¼Œç›´æ¥å„²å­˜åŸå§‹æ–‡å­—")
        
            punctuation_choice = input("è«‹é¸æ“‡ (1-2): ").strip()
        
            if punctuation_choice == "1":
                # éœ€è¦ API Key é€²è¡Œæ¨™é»ç¬¦è™Ÿè™•ç†
                api_key = get_api_key()
                if api_key:
                    
                    with open(os.path.join(output_path, f"{video_title}_unpunctuated.txt"), "w", encoding="utf-8") as f:
                        f.write(traditional_text)
                    
                    client = openai.OpenAI(api_key=api_key)
                    punctuated_text = process_text_with_punctuation(traditional_text, client)
                    
                    # å„²å­˜å¸¶æ¨™é»ç¬¦è™Ÿçš„ç‰ˆæœ¬
                    save_file(used_method, output_filename, punctuated_text)
                else:
                    print("âŒ ç„¡æ³•å–å¾— API Keyï¼Œå„²å­˜åŸå§‹æ–‡å­—")
                    save_file(used_method, os.path.join(output_path, f"{video_title}_unpunctuated.txt"), traditional_text)
        else:
            save_file(used_method, output_filename, traditional_text)
    else:
        print("\nâŒ è½‰éŒ„å¤±æ•—")
